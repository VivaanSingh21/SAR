Warning: Log dir /home/biorobotics/DCS_testing/SAR/data/dmc.cheetah.run/Dyn-Ba2-t-sar-curl-sac-euf_qf1-CFmax_5.7_min_mu_16-nrs5-rsfc0.8/Dyn-Ba2-t-sar-curl-sac-euf_qf1-CFmax_5.7_min_mu_16-nrs5-rsfc0.8_s0 already exists! Storing info there anyway.
[32;1mLogging data to /home/biorobotics/DCS_testing/SAR/data/dmc.cheetah.run/Dyn-Ba2-t-sar-curl-sac-euf_qf1-CFmax_5.7_min_mu_16-nrs5-rsfc0.8/Dyn-Ba2-t-sar-curl-sac-euf_qf1-CFmax_5.7_min_mu_16-nrs5-rsfc0.8_s0/progress.txt[0m
[36;1mSaving config:
[0m
{
    "agent":	"curl",
    "agent_base_params":	{
        "action_repeat":	4,
        "actor_update_freq":	2,
        "actor_update_mode":	"sum",
        "critic_target_update_freq":	2,
        "extr_update_freq_via_qfloss":	1,
        "extr_update_via_qfloss":	true,
        "num":	2,
        "num_sources":	2,
        "update_to_data":	1
    },
    "agent_params":	{
        "extr_beta":	0.9,
        "extr_lr":	0.0005,
        "image_pad":	4
    },
    "algo_params":	{
        "actor_beta":	0.9,
        "actor_log_std_max":	2,
        "actor_log_std_min":	-5,
        "actor_lr":	0.0005,
        "alpha_beta":	0.5,
        "alpha_lr":	0.0005,
        "critic_beta":	0.9,
        "critic_lr":	0.0005,
        "critic_tau":	0.01,
        "critic_type":	"ensemble",
        "extr_latent_dim":	50,
        "hidden_dim":	1024,
        "init_temperature":	0.1,
        "l":	2,
        "num_q":	2,
        "num_targ_q":	2,
        "std_clip":	0.3
    },
    "auxiliary":	"sar",
    "auxiliary_params":	{
        "act_seq_out_dim":	5,
        "discount_of_rs":	0.8,
        "extr_beta":	0.9,
        "extr_latent_dim":	50,
        "extr_lr":	0.0005,
        "hidden_dim":	1024,
        "l":	2,
        "nstep_of_rsd":	5,
        "num_sample":	16,
        "omega_opt_mode":	"min_mu",
        "omg_seq_out_dim":	5,
        "opt_mode":	"max",
        "opt_num":	5,
        "output_dim":	7,
        "rs_fc":	true,
        "temperature":	0.1
    },
    "base":	"sac",
    "buffer_params":	{
        "capacity":	100000,
        "gamma":	0.99,
        "image_size":	84,
        "nstep":	1,
        "nstep_of_rsd":	5,
        "save_buffer":	false
    },
    "data_aug":	"shift",
    "env":	"dmc.cheetah.run",
    "evaluation":	false,
    "exp_name":	"Dyn-Ba2-t-sar-curl-sac-euf_qf1-CFmax_5.7_min_mu_16-nrs5-rsfc0.8",
    "extr_params":	{
        "extr_latent_dim":	50,
        "extr_tau":	0.05,
        "num_fc":	2,
        "num_filters":	32,
        "num_layers":	4,
        "targ_extr":	1
    },
    "max_ep_len":	1000,
    "setting":	{
        "background":	true,
        "background_dataset_path":	"/home/biorobotics/Downloads/DAVIS/JPEGImages/480p",
        "camera":	false,
        "camera_scale":	0.1,
        "color":	false,
        "color_scale":	0.1,
        "difficulty":	"easy",
        "distract_mode":	"train",
        "dynamic":	true,
        "frame_stack":	3,
        "num_sources":	2,
        "num_videos":	4,
        "seed":	0,
        "test_camera_scale":	0.1,
        "test_color_scale":	0.1
    },
    "steps_per_epoch":	8000,
    "train_params":	{
        "action_repeat":	4,
        "eval_freq":	2000,
        "init_steps":	1,
        "num_eval_episodes":	10,
        "save_model":	true,
        "save_model_freq":	5,
        "test":	true,
        "total_steps":	500000
    },
    "wandb_api_key":	"77a28a62dfa6134ec25161511f1049fa8fec49da"
}
Runing DMC env...
background: True, camera: False, color: False
{'dataset_path': '/home/biorobotics/Downloads/DAVIS/JPEGImages/480p', 'dataset_videos': 'train', 'num_videos': 4, 'video_alpha': 1.0, 'ground_plane_alpha': 1.0, 'dynamic': True, 'shuffle_buffer_size': None}
/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/gym/spaces/box.py:127: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  logger.warn(f"Box bound precision lowered by casting to {self.dtype}")
{'dataset_path': '/home/biorobotics/Downloads/DAVIS/JPEGImages/480p', 'dataset_videos': 'train', 'num_videos': 4, 'video_alpha': 1.0, 'ground_plane_alpha': 1.0, 'dynamic': True, 'shuffle_buffer_size': None}
BACKGROUND KWARGS {'num_videos': None, 'video_alpha': 1.0, 'ground_plane_alpha': 1.0, 'dynamic': True, 'dataset_path': '/home/biorobotics/Downloads/DAVIS/JPEGImages/480p', 'dataset_videos': 'val', 'shuffle_buffer_size': None}
{'dataset_path': '/home/biorobotics/Downloads/DAVIS/JPEGImages/480p', 'dataset_videos': 'val', 'num_videos': None, 'video_alpha': 1.0, 'ground_plane_alpha': 1.0, 'dynamic': True, 'shuffle_buffer_size': None}
dmc.cheetah.run
39200 50 1024 6
Augment: RandomShiftsAug_84()
AuxiliaryTask: CFAPredictor(
  (aseq_fc): Sequential(
    (0): Linear(in_features=30, out_features=5, bias=True)
  )
  (omeg_fc): Sequential(
    (0): Linear(in_features=5, out_features=5, bias=True)
  )
  (rseq_fc): Sequential(
    (0): Linear(in_features=5, out_features=5, bias=True)
  )
  (predictor): Sequential(
    (0): Linear(in_features=60, out_features=1024, bias=True)
    (1): Swish()
    (2): Linear(in_features=1024, out_features=1024, bias=True)
    (3): Swish()
    (4): Linear(in_features=1024, out_features=14, bias=True)
  )
)
Extractor: PixelExtractor(
  (convs): ModuleList(
    (0): Conv2d(9, 32, kernel_size=(3, 3), stride=(2, 2))
    (1-3): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  )
)
Target Extractor: PixelExtractor(
  (convs): ModuleList(
    (0): Conv2d(9, 32, kernel_size=(3, 3), stride=(2, 2))
    (1-3): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
  )
)
Critic: EnsembleCritic(
  (trunk): Sequential(
    (0): Linear(in_features=39200, out_features=50, bias=True)
    (1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
  )
  (q): Sequential(
    (0): EnsembleLinear(in_features=56, out_features=1024, in_channels=2, bias=True)
    (1): ReLU(inplace=True)
    (2): EnsembleLinear(in_features=1024, out_features=1024, in_channels=2, bias=True)
    (3): ReLU(inplace=True)
    (4): EnsembleLinear(in_features=1024, out_features=1, in_channels=2, bias=True)
  )
)
Actor: SGMLPActor(
  (trunk): Sequential(
    (0): Linear(in_features=39200, out_features=50, bias=True)
    (1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
  )
  (pi_trunk): Sequential(
    (0): Linear(in_features=50, out_features=1024, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=1024, out_features=1024, bias=True)
    (3): ReLU(inplace=True)
  )
  (pi_mean): Sequential(
    (0): Linear(in_features=1024, out_features=6, bias=True)
  )
  (pi_logstd): Sequential(
    (0): Linear(in_features=1024, out_features=6, bias=True)
  )
)
CURL: CURL(
  (extr): PixelExtractor(
    (convs): ModuleList(
      (0): Conv2d(9, 32, kernel_size=(3, 3), stride=(2, 2))
      (1-3): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    )
  )
  (trunk): Sequential(
    (0): Linear(in_features=39200, out_features=50, bias=True)
    (1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
  )
  (extr_targ): PixelExtractor(
    (convs): ModuleList(
      (0): Conv2d(9, 32, kernel_size=(3, 3), stride=(2, 2))
      (1-3): 3 x Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    )
  )
  (trunk_targ): Sequential(
    (0): Linear(in_features=39200, out_features=50, bias=True)
    (1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
  )
)
<class 'numpy.ndarray'>
Total T: 250 Reward: 9.209 Episode Num: 0 Episode T: 250 Time: 0:00:05
<class 'numpy.ndarray'>
Total T: 500 Reward: 8.115 Episode Num: 1 Episode T: 250 Time: 0:00:10
<class 'numpy.ndarray'>
Total T: 750 Reward: 10.576 Episode Num: 2 Episode T: 250 Time: 0:00:15
<class 'numpy.ndarray'>
Total T: 1000 Reward: 8.102 Episode Num: 3 Episode T: 250 Time: 0:00:20
<class 'numpy.ndarray'>
Total T: 1250 Reward: 6.687 Episode Num: 4 Episode T: 250 Time: 0:00:25
<class 'numpy.ndarray'>
Total T: 1500 Reward: 8.453 Episode Num: 5 Episode T: 250 Time: 0:00:30
<class 'numpy.ndarray'>
Total T: 1750 Reward: 8.486 Episode Num: 6 Episode T: 250 Time: 0:00:35
<class 'numpy.ndarray'>
Total T: 2000 Reward: 11.138 Episode Num: 7 Episode T: 250 Time: 0:00:40
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
Printing evaluation metrics
 /n episode rewards3.4958859495789616
/n  # of episodes 2000
Update Extr Times: 0 Update Critic Times: 0 Update Actor Times: 0
Total T: 2250 Reward: 7.082 Episode Num: 8 Episode T: 250 Time: 0:01:34
<class 'numpy.ndarray'>
Total T: 2500 Reward: 9.975 Episode Num: 9 Episode T: 250 Time: 0:01:39
<class 'numpy.ndarray'>
Total T: 2750 Reward: 8.609 Episode Num: 10 Episode T: 250 Time: 0:01:44
<class 'numpy.ndarray'>
Total T: 3000 Reward: 7.203 Episode Num: 11 Episode T: 250 Time: 0:01:48
<class 'numpy.ndarray'>
Total T: 3250 Reward: 12.517 Episode Num: 12 Episode T: 250 Time: 0:01:53
<class 'numpy.ndarray'>
Total T: 3500 Reward: 8.767 Episode Num: 13 Episode T: 250 Time: 0:01:58
<class 'numpy.ndarray'>
Total T: 3750 Reward: 6.939 Episode Num: 14 Episode T: 250 Time: 0:02:03
<class 'numpy.ndarray'>
Total T: 4000 Reward: 9.004 Episode Num: 15 Episode T: 250 Time: 0:02:08
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
Printing evaluation metrics
 /n episode rewards3.771583552796301
/n  # of episodes 4000
Update Extr Times: 0 Update Critic Times: 0 Update Actor Times: 0
Total T: 4250 Reward: 7.821 Episode Num: 16 Episode T: 250 Time: 0:03:03
<class 'numpy.ndarray'>
Total T: 4500 Reward: 7.958 Episode Num: 17 Episode T: 250 Time: 0:03:08
<class 'numpy.ndarray'>
Total T: 4750 Reward: 8.053 Episode Num: 18 Episode T: 250 Time: 0:03:13
<class 'numpy.ndarray'>
Total T: 5000 Reward: 6.570 Episode Num: 19 Episode T: 250 Time: 0:03:18
<class 'numpy.ndarray'>
Total T: 5250 Reward: 11.475 Episode Num: 20 Episode T: 250 Time: 0:03:23
<class 'numpy.ndarray'>
Total T: 5500 Reward: 10.494 Episode Num: 21 Episode T: 250 Time: 0:03:28
<class 'numpy.ndarray'>
Total T: 5750 Reward: 9.990 Episode Num: 22 Episode T: 250 Time: 0:03:33
<class 'numpy.ndarray'>
Total T: 6000 Reward: 8.064 Episode Num: 23 Episode T: 250 Time: 0:03:38
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
Traceback (most recent call last):
  File "launch.py", line 129, in <module>
    run(args, device, work_dir, config)
  File "launch.py", line 94, in run
    train_agent(train_envs=train_envs,
  File "/home/biorobotics/DCS_testing/SAR/train.py", line 158, in train_agent
    evaluate(test_env, agent, logger, video, num_eval_episodes,
  File "/home/biorobotics/DCS_testing/SAR/train.py", line 89, in evaluate
    eval(0, test_env, agent, logger, video, num_eval_episodes,
  File "/home/biorobotics/DCS_testing/SAR/train.py", line 30, in eval
    action = agent.select_action(obs, deterministic=True)
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/biorobotics/DCS_testing/SAR/agent/agent_base.py", line 121, in select_action
    return self.rl.select_action(s, deterministic, tanh, to_numpy)
  File "/home/biorobotics/DCS_testing/SAR/algo/algo_base.py", line 37, in select_action
    pi = self.actor.act(s, deterministic, tanh)
  File "/home/biorobotics/DCS_testing/SAR/module/rl_module.py", line 93, in act
    mu_action, pi_action, _, _ = self.forward(state, not deterministic, False, tanh)
  File "/home/biorobotics/DCS_testing/SAR/module/rl_module.py", line 72, in forward
    mu, log_std, _ = self.dist(state, tanh)
  File "/home/biorobotics/DCS_testing/SAR/module/rl_module.py", line 58, in dist
    h = self.pi_trunk(self.forward_trunk(state, tanh))
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/biorobotics/miniconda3/envs/sar_env/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
